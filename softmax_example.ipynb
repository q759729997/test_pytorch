{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "softmax_example.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/q759729997/test_pytorch/blob/master/softmax_example.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VVbmxeH-G_0c",
        "colab_type": "text"
      },
      "source": [
        "# softmax回归简洁实现"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S5BCGvuZG0_b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HOdkzVMFGAEk",
        "colab_type": "text"
      },
      "source": [
        "读取数据集"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V3FfJQuJGWlm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torchvision\n",
        "import sys"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tJueiU86GEXq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_data_fashion_mnist(batch_size, resize=None, root='~/Datasets/FashionMNIST'):\n",
        "  \"\"\"Download the fashion mnist dataset and then load into memory.\"\"\"\n",
        "  trans = []\n",
        "  if resize:\n",
        "    trans.append(torchvision.transforms.Resize(size=resize))\n",
        "  trans.append(torchvision.transforms.ToTensor())\n",
        "  \n",
        "  transform = torchvision.transforms.Compose(trans)\n",
        "  mnist_train = torchvision.datasets.FashionMNIST(root=root, train=True, download=True, transform=transform)\n",
        "  mnist_test = torchvision.datasets.FashionMNIST(root=root, train=False, download=True, transform=transform)\n",
        "  if sys.platform.startswith('win'):\n",
        "    num_workers = 0  # 0表示不用额外的进程来加速读取数据\n",
        "  else:\n",
        "    num_workers = 4\n",
        "  train_iter = torch.utils.data.DataLoader(mnist_train, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
        "  test_iter = torch.utils.data.DataLoader(mnist_test, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
        "\n",
        "  return train_iter, test_iter"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "unwulKDtGmAS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "outputId": "18a9b381-5415-4618-8304-bff7c95fa01d"
      },
      "source": [
        "batch_size = 256\n",
        "train_iter,test_iter = load_data_fashion_mnist(batch_size)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 16384/26421880 [00:00<02:57, 148654.33it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to /root/Datasets/FashionMNIST/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "26427392it [00:00, 74248827.92it/s]                            \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting /root/Datasets/FashionMNIST/FashionMNIST/raw/train-images-idx3-ubyte.gz to /root/Datasets/FashionMNIST/FashionMNIST/raw\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "32768it [00:00, 472287.45it/s]\n",
            "  2%|▏         | 98304/4422102 [00:00<00:04, 967795.90it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to /root/Datasets/FashionMNIST/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n",
            "Extracting /root/Datasets/FashionMNIST/FashionMNIST/raw/train-labels-idx1-ubyte.gz to /root/Datasets/FashionMNIST/FashionMNIST/raw\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to /root/Datasets/FashionMNIST/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "4423680it [00:00, 23970454.92it/s]                         \n",
            "8192it [00:00, 149350.56it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting /root/Datasets/FashionMNIST/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to /root/Datasets/FashionMNIST/FashionMNIST/raw\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to /root/Datasets/FashionMNIST/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n",
            "Extracting /root/Datasets/FashionMNIST/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to /root/Datasets/FashionMNIST/FashionMNIST/raw\n",
            "Processing...\n",
            "Done!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uuAc7GD7G6mr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 定义模型\n",
        "class FlattenLayer(torch.nn.Module):\n",
        "  def __init__(self):\n",
        "    super(FlattenLayer, self).__init__()\n",
        "  def forward(self, x): # x shape: (batch, *, *, ...)\n",
        "    return x.view(x.shape[0], -1)\n",
        "\n",
        "num_inputs = 784\n",
        "num_outputs = 10\n",
        "\n",
        "class SoftMaxNet(torch.nn.Module):\n",
        "  def __init__(self, num_inputs, num_outputs):\n",
        "    super(SoftMaxNet, self).__init__()\n",
        "    self.flatten = FlattenLayer()\n",
        "    self.linear = torch.nn.Linear(num_inputs, num_outputs)\n",
        "  def forward(self, x): # x shape: (batch, 1, 28, 28)\n",
        "    # y = self.linear(x.view(x.shape[0], -1))\n",
        "    y = self.linear(self.flatten(x))\n",
        "    return self.softmax(y)\n",
        "  \n",
        "  def softmax(self,X):\n",
        "    X_exp = X.exp()\n",
        "    partition = X_exp.sum(dim=1, keepdim=True)\n",
        "    return X_exp / partition  # 这里应用了广播机制\n",
        "    \n",
        "net = SoftMaxNet(num_inputs, num_outputs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oHbyI8XhIRG_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "outputId": "b407300a-0a3f-4e09-e494-ad3175925078"
      },
      "source": [
        "print(net)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SoftMaxNet(\n",
            "  (flatten): FlattenLayer()\n",
            "  (linear): Linear(in_features=784, out_features=10, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "coW9FulTIdqj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2a3c14fd-273a-4ca4-c59b-a0d8fcd3ae98"
      },
      "source": [
        "# 损失函数\n",
        "loss = torch.nn.CrossEntropyLoss()\n",
        "print(loss)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CrossEntropyLoss()\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZT2yJyq7I5Tc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 定义优化算法\n",
        "optimizer = torch.optim.Adam(net.parameters())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KNP8QNjyJOYz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 151
        },
        "outputId": "0a6aa1ec-59f6-4f04-8947-aa70acd624dd"
      },
      "source": [
        "print(optimizer)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Adam (\n",
            "Parameter Group 0\n",
            "    amsgrad: False\n",
            "    betas: (0.9, 0.999)\n",
            "    eps: 1e-08\n",
            "    lr: 0.001\n",
            "    weight_decay: 0\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n3odLzjKJq93",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate_accuracy(data_iter, net):\n",
        "  acc_sum, n = 0.0, 0\n",
        "  for X, y in data_iter:\n",
        "    acc_sum += (net(X).argmax(dim=1) == y).float().sum().item()\n",
        "    n += y.shape[0]\n",
        "  return acc_sum / n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q5ieUxR9JRaL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 训练模型\n",
        "def train_ch3(net, train_iter, test_iter, loss, num_epochs, batch_size, optimizer=None):\n",
        "  for epoch in range(num_epochs):\n",
        "    train_l_sum, train_acc_sum, n = 0.0, 0.0, 0\n",
        "    for X, y in train_iter:\n",
        "      y_hat = net(X)\n",
        "      l = loss(y_hat, y).sum()\n",
        "      # 梯度清零\n",
        "      optimizer.zero_grad()\n",
        "      l.backward()\n",
        "      optimizer.step()\n",
        "      train_l_sum += l.item()\n",
        "      # 按指定的维度返回最大元素的坐标\n",
        "      train_acc_sum += (y_hat.argmax(dim=1) == y).sum().item()\n",
        "      n += y.shape[0]\n",
        "    test_acc = evaluate_accuracy(test_iter, net)\n",
        "    print('epoch %d, loss %.4f, train acc %.3f, test acc %.3f'\n",
        "          % (epoch + 1, train_l_sum / n, train_acc_sum / n, test_acc))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pSNqf7SSKHPo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        },
        "outputId": "f54c6141-e6e4-4d27-80ec-809062a793b1"
      },
      "source": [
        "num_epochs = 5\n",
        "train_ch3(net, train_iter, test_iter, loss, num_epochs, batch_size, optimizer)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch 1, loss 0.0072, train acc 0.689, test acc 0.753\n",
            "epoch 2, loss 0.0067, train acc 0.795, test acc 0.801\n",
            "epoch 3, loss 0.0066, train acc 0.819, test acc 0.816\n",
            "epoch 4, loss 0.0065, train acc 0.828, test acc 0.823\n",
            "epoch 5, loss 0.0065, train acc 0.835, test acc 0.824\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9jSY38Q4LHNe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 420
        },
        "outputId": "706f28c4-1fe1-4a68-83b3-6dcaf5ef6bd5"
      },
      "source": [
        "# 测试\n",
        "for X, y in train_iter:\n",
        "  y_hat = net(X)\n",
        "  print(y_hat)\n",
        "  # 按指定的维度返回最大元素的坐标\n",
        "  print(y_hat.argmax(dim=1))\n",
        "  break"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[7.0121e-13, 6.7845e-14, 1.6505e-06,  ..., 1.1991e-11, 9.9999e-01,\n",
            "         1.2302e-06],\n",
            "        [1.7142e-06, 2.9782e-06, 1.0952e-01,  ..., 2.1148e-09, 4.9318e-04,\n",
            "         7.6909e-06],\n",
            "        [1.5868e-10, 1.9363e-09, 1.3098e-08,  ..., 9.9980e-01, 3.4598e-05,\n",
            "         1.2609e-05],\n",
            "        ...,\n",
            "        [1.7845e-09, 4.0784e-08, 5.4013e-07,  ..., 9.8444e-01, 1.9268e-04,\n",
            "         5.6761e-04],\n",
            "        [7.9065e-05, 1.1106e-04, 1.5078e-03,  ..., 8.7471e-08, 4.0056e-01,\n",
            "         1.6939e-05],\n",
            "        [2.5133e-07, 7.6533e-13, 1.3707e-06,  ..., 9.0330e-12, 9.9999e-01,\n",
            "         3.2008e-06]], grad_fn=<DivBackward0>)\n",
            "tensor([8, 6, 7, 0, 0, 4, 1, 7, 8, 4, 8, 4, 9, 7, 8, 9, 9, 8, 0, 1, 0, 7, 5, 0,\n",
            "        0, 2, 2, 0, 8, 8, 0, 9, 4, 1, 3, 0, 2, 7, 1, 5, 2, 2, 0, 7, 0, 0, 9, 5,\n",
            "        1, 2, 3, 0, 3, 0, 8, 4, 5, 1, 4, 7, 5, 2, 7, 5, 2, 5, 0, 4, 3, 0, 7, 8,\n",
            "        1, 3, 2, 1, 3, 5, 7, 7, 9, 9, 5, 4, 8, 6, 0, 3, 4, 1, 0, 6, 8, 5, 9, 3,\n",
            "        3, 4, 5, 5, 0, 1, 7, 0, 4, 3, 7, 9, 3, 2, 1, 0, 1, 9, 4, 4, 0, 1, 7, 3,\n",
            "        5, 0, 1, 9, 5, 1, 1, 1, 7, 0, 1, 1, 0, 3, 9, 1, 4, 8, 0, 0, 9, 7, 7, 4,\n",
            "        8, 7, 9, 3, 9, 0, 0, 2, 6, 1, 6, 6, 0, 8, 0, 0, 8, 7, 0, 5, 1, 0, 5, 7,\n",
            "        2, 5, 0, 7, 8, 0, 9, 9, 2, 7, 0, 2, 9, 4, 7, 1, 7, 0, 7, 2, 0, 9, 3, 3,\n",
            "        4, 0, 7, 6, 3, 8, 0, 3, 6, 1, 3, 2, 7, 3, 5, 5, 2, 4, 9, 0, 8, 8, 4, 7,\n",
            "        5, 9, 8, 7, 8, 2, 0, 7, 5, 0, 8, 4, 5, 7, 4, 0, 2, 5, 6, 3, 1, 0, 5, 2,\n",
            "        7, 2, 5, 6, 0, 5, 8, 9, 4, 3, 3, 5, 1, 7, 4, 8])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1cdJm2PWNyX0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "outputId": "400573c0-c6f1-4bd6-e077-a12b4268728e"
      },
      "source": [
        "def softmax(X):\n",
        "  X_exp = X.exp()\n",
        "  partition = X_exp.sum(dim=1, keepdim=True)\n",
        "  return X_exp / partition  # 这里应用了广播机制\n",
        "\n",
        "X = torch.rand((2, 5))\n",
        "X_prob = softmax(X)\n",
        "print(X)\n",
        "print(X_prob, X_prob.sum(dim=1))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0.0168, 0.7681, 0.8237, 0.8822, 0.7445],\n",
            "        [0.8182, 0.6885, 0.2124, 0.1123, 0.5423]])\n",
            "tensor([[0.1020, 0.2162, 0.2285, 0.2423, 0.2111],\n",
            "        [0.2720, 0.2389, 0.1484, 0.1343, 0.2064]]) tensor([1., 1.])\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}